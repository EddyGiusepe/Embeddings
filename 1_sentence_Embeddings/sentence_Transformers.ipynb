{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Sentence Transformers: Sentence Embedding, Sentence Similarity, Semantic Search and Clustering |Code</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scientist.: Dr.Eddy Giusepe Chirinos Isidro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links de estudos:\n",
    "\n",
    "* [semantic-similarity](https://github.com/abhinavthomas/semantic-similarity)\n",
    "\n",
    "* [Sentence Transformers](https://www.youtube.com/watch?v=OlhNZg4gOvA)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">É o nome coletivo para um conjunto de técnicas em processamento de linguagem natural (NLP) onde as sentenças são mapeadas para vetores de números reais .</font>\n",
    "\n",
    "Casos de uso:\n",
    "\n",
    "* Sentence Embedding\n",
    "\n",
    "* Sentence Similarity\n",
    "\n",
    "* Semantic Search\n",
    "\n",
    "* Clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerando Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Carregamos o Modelo pré-treinado ---> https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "             'Sentences are passed as a list of string.']\n",
    "\n",
    "\n",
    "embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 384)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: This framework generates embeddings for each input sentence\n",
      "Embedding: [-1.37173841e-02 -4.28515412e-02 -1.56286340e-02  1.40537862e-02\n",
      "  3.95537652e-02  1.21796295e-01  2.94333789e-02 -3.17524001e-02\n",
      "  3.54959518e-02 -7.93140009e-02  1.75878368e-02 -4.04369719e-02\n",
      "  4.97259907e-02  2.54912432e-02 -7.18699992e-02  8.14968348e-02\n",
      "  1.47069513e-03  4.79627140e-02 -4.50335890e-02 -9.92174968e-02\n",
      " -2.81769503e-02  6.45046309e-02  4.44670804e-02 -4.76217270e-02\n",
      " -3.52952182e-02  4.38671783e-02 -5.28565720e-02  4.33049776e-04\n",
      "  1.01921476e-01  1.64072402e-02  3.26996855e-02 -3.45986858e-02\n",
      "  1.21339634e-02  7.94871226e-02  4.58342116e-03  1.57778692e-02\n",
      " -9.68206860e-03  2.87626293e-02 -5.05806319e-02 -1.55793894e-02\n",
      " -2.87907142e-02 -9.62278992e-03  3.15556526e-02  2.27349550e-02\n",
      "  8.71449485e-02 -3.85027640e-02 -8.84718820e-02 -8.75497609e-03\n",
      " -2.12343279e-02  2.08924059e-02 -9.02078152e-02 -5.25732487e-02\n",
      " -1.05638532e-02  2.88311187e-02 -1.61454845e-02  6.17841305e-03\n",
      " -1.23234503e-02 -1.07337097e-02  2.83353571e-02 -5.28567918e-02\n",
      " -3.58618163e-02 -5.97989298e-02 -1.09055080e-02  2.91566681e-02\n",
      "  7.97979236e-02 -3.27899150e-04  6.83498429e-03  1.32718449e-02\n",
      " -4.24619950e-02  1.87656526e-02 -9.89234746e-02  2.09049843e-02\n",
      " -8.69605616e-02 -1.50152035e-02 -4.86202314e-02  8.04414824e-02\n",
      " -3.67700798e-03 -6.65044188e-02  1.14556760e-01 -3.04228645e-02\n",
      "  2.96631530e-02 -2.80695185e-02  4.64990363e-02 -2.25513615e-02\n",
      "  8.54222700e-02  3.15446928e-02  7.34542012e-02 -2.21861936e-02\n",
      " -5.29679023e-02  1.27130179e-02 -5.27339764e-02 -1.06188744e-01\n",
      "  7.04731569e-02  2.76736636e-02 -8.05531442e-02  2.39649676e-02\n",
      " -2.65125055e-02 -2.17330996e-02  4.35275324e-02  4.84712049e-02\n",
      " -2.37066988e-02  2.85768192e-02  1.11846142e-01 -6.34936020e-02\n",
      " -1.58318523e-02 -2.26169731e-02 -1.31028285e-02 -1.62068591e-03\n",
      " -3.60928662e-02 -9.78297293e-02 -4.67729084e-02  1.76272243e-02\n",
      " -3.97492349e-02 -1.76448244e-04  3.39627750e-02 -2.09633522e-02\n",
      "  6.33661309e-03 -2.59411857e-02  8.10410604e-02  6.14393242e-02\n",
      " -5.44598605e-03  6.48275986e-02 -1.16844065e-01  2.36861110e-02\n",
      " -1.32058514e-02 -1.12476446e-01  1.90049447e-02 -1.74658968e-34\n",
      "  5.58949523e-02  1.94244795e-02  4.65438776e-02  5.18645830e-02\n",
      "  3.89390141e-02  3.40540893e-02 -4.32114266e-02  7.90637136e-02\n",
      " -9.79530141e-02 -1.27441091e-02 -2.91870981e-02  1.02052270e-02\n",
      "  1.88115891e-02  1.08942531e-01  6.63465112e-02 -5.35295382e-02\n",
      " -3.29228863e-02  4.69826795e-02  2.28883214e-02  2.74114534e-02\n",
      " -2.91983243e-02  3.12706642e-02 -2.22850461e-02 -1.02282166e-01\n",
      " -2.79116370e-02  1.13793407e-02  9.06309262e-02 -4.75414507e-02\n",
      " -1.00718968e-01 -1.23232063e-02 -7.96928406e-02 -1.44636435e-02\n",
      " -7.76400566e-02 -7.66921369e-03  9.73955821e-03  2.24204883e-02\n",
      "  7.77267963e-02 -3.17157479e-03  2.11538486e-02 -3.30393873e-02\n",
      "  9.55250487e-03 -3.73012237e-02  2.61360556e-02 -9.79084056e-03\n",
      " -6.31505400e-02  5.77433687e-03 -3.80031243e-02  1.29684238e-02\n",
      " -1.82498805e-02 -1.56282876e-02 -1.23362686e-03  5.55579253e-02\n",
      "  1.13087401e-04 -5.61256818e-02  7.40165934e-02  1.84452012e-02\n",
      " -2.66368203e-02  1.31951589e-02  7.50086904e-02 -2.46797390e-02\n",
      " -3.24006155e-02 -1.57675035e-02 -8.03517550e-03 -5.61320223e-03\n",
      "  1.05687892e-02  3.26168141e-03 -3.91989946e-02 -9.38677266e-02\n",
      "  1.14227176e-01  6.57304749e-02 -4.72633429e-02  1.45087652e-02\n",
      " -3.54490094e-02 -3.37761380e-02 -5.15506342e-02 -3.80997593e-03\n",
      " -5.15036546e-02 -5.93429282e-02 -1.69410894e-03  7.42107481e-02\n",
      " -4.20091264e-02 -7.19975084e-02  3.17249820e-02 -1.66303311e-02\n",
      "  3.96983791e-03 -6.52750656e-02  2.77391225e-02 -7.51649812e-02\n",
      "  2.27456000e-02 -3.91368233e-02  1.54316192e-02 -5.54908328e-02\n",
      "  1.23318434e-02 -2.59520765e-02  6.66423514e-02 -6.91259876e-34\n",
      "  3.31628658e-02  8.47929120e-02 -6.65584430e-02  3.33541296e-02\n",
      "  4.71607829e-03  1.35361860e-02 -5.38694449e-02  9.20693949e-02\n",
      " -2.96876840e-02  3.16219702e-02 -2.37497333e-02  1.98771190e-02\n",
      "  1.03446193e-01 -9.06947330e-02  6.30627153e-03  1.42886229e-02\n",
      "  1.19293779e-02  6.43726392e-03  4.20104526e-02  1.25344396e-02\n",
      "  3.93019393e-02  5.35691492e-02 -4.30749804e-02  6.10432625e-02\n",
      " -5.39394241e-05  6.91682696e-02  1.05520478e-02  1.22111905e-02\n",
      " -7.23185390e-02  2.50469334e-02 -5.18370867e-02 -4.36562300e-02\n",
      " -6.71818629e-02  1.34828007e-02 -7.25888610e-02  7.04164105e-03\n",
      "  6.58939332e-02  1.08994124e-02 -2.60009826e-03  5.49968854e-02\n",
      "  5.06966747e-02  3.27948406e-02 -6.68832958e-02  6.45557120e-02\n",
      " -2.52076406e-02 -2.92571858e-02 -1.16696730e-01  3.24064493e-02\n",
      "  5.85858636e-02 -3.51756588e-02 -7.15239942e-02  2.24936102e-02\n",
      " -1.00786716e-01 -4.74545211e-02 -7.61962608e-02 -5.87166883e-02\n",
      "  4.21138443e-02 -7.47213811e-02  1.98468156e-02 -3.36504891e-03\n",
      " -5.29736727e-02  2.74729040e-02  3.45736817e-02 -6.11847006e-02\n",
      "  1.06364764e-01 -9.64120030e-02 -4.55945209e-02  1.51489777e-02\n",
      " -5.13529405e-03 -6.64447397e-02  4.31720987e-02 -1.10406093e-02\n",
      " -9.80249606e-03  7.53783211e-02 -1.49570955e-02 -4.80208583e-02\n",
      "  5.80726266e-02 -2.43896693e-02 -2.23138109e-02 -4.36992832e-02\n",
      "  5.12054376e-02 -3.28625701e-02  1.08763322e-01  6.08926490e-02\n",
      "  3.30790854e-03  5.53819723e-02  8.43200982e-02  1.27087291e-02\n",
      "  3.84465680e-02  6.52325600e-02 -2.94683818e-02  5.08005731e-02\n",
      " -2.09347848e-02  1.46135658e-01  2.25561578e-02 -1.77227761e-08\n",
      " -5.02673015e-02 -2.79219705e-04 -1.00328565e-01  2.42811181e-02\n",
      " -7.54043460e-02 -3.79139669e-02  3.96049917e-02  3.10079698e-02\n",
      " -9.05702915e-03 -6.50411770e-02  4.05453481e-02  4.83390279e-02\n",
      " -4.56962176e-02  4.76004882e-03  2.64362199e-03  9.35614258e-02\n",
      " -4.02599201e-02  3.27401906e-02  1.18298456e-02  5.54344542e-02\n",
      "  1.48052230e-01  7.21189231e-02  2.76972918e-04  1.68651342e-02\n",
      "  8.34882911e-03 -8.76154192e-03 -1.33649986e-02  6.14236929e-02\n",
      "  1.57167800e-02  6.94960952e-02  1.08621614e-02  6.08018637e-02\n",
      " -5.33421077e-02 -3.47924680e-02 -3.36272009e-02  6.93906918e-02\n",
      "  1.22987889e-02 -1.45237327e-01 -2.06971099e-03 -4.61132750e-02\n",
      "  3.72746703e-03 -5.59356343e-03 -1.00659877e-01 -4.45952825e-02\n",
      "  5.40921092e-02  4.98892693e-03  1.49534727e-02 -8.26059356e-02\n",
      "  6.26630783e-02 -5.01910038e-03 -4.81857695e-02 -3.53991203e-02\n",
      "  9.03388951e-03 -2.42337808e-02  5.66267110e-02  2.51529180e-02\n",
      " -1.70709249e-02 -1.24779828e-02  3.19518112e-02  1.38420872e-02\n",
      " -1.55814942e-02  1.00178309e-01  1.23657264e-01 -4.22967039e-02]\n",
      "\n",
      "Sentence: Sentences are passed as a list of string.\n",
      "Embedding: [ 5.64524755e-02  5.50023727e-02  3.13795693e-02  3.39485109e-02\n",
      " -3.54246795e-02  8.34667459e-02  9.88800824e-02  7.27544678e-03\n",
      " -6.68661157e-03 -7.65807647e-03  7.93738663e-02  7.39695504e-04\n",
      "  1.49291996e-02 -1.51046785e-02  3.67674306e-02  4.78743315e-02\n",
      " -4.81969528e-02 -3.76052447e-02 -4.60277982e-02 -8.89816135e-02\n",
      "  1.20228179e-01  1.30663276e-01 -3.73936184e-02  2.47855694e-03\n",
      "  2.55824300e-03  7.25814551e-02 -6.80436417e-02 -5.24696074e-02\n",
      "  4.90234196e-02  2.99563501e-02 -5.84429763e-02 -2.02262867e-02\n",
      "  2.08821986e-02  9.76691693e-02  3.52390856e-02  3.91141213e-02\n",
      "  1.05668213e-02  1.56230689e-03 -1.30822621e-02  8.52902606e-03\n",
      " -4.84094443e-03 -2.03766469e-02 -2.71801036e-02  2.83307694e-02\n",
      "  3.66017818e-02  2.51276251e-02 -9.90862027e-02  1.15626380e-02\n",
      " -3.60380560e-02 -7.23783970e-02 -1.12670131e-01  1.12942066e-02\n",
      " -3.86397652e-02  4.67385948e-02 -2.88460478e-02  2.26703640e-02\n",
      " -8.52401741e-03  3.32815051e-02 -1.06581068e-03 -7.09745064e-02\n",
      " -6.31169900e-02 -5.72186820e-02 -6.16026483e-02  5.47146462e-02\n",
      "  1.18317781e-02 -4.66261394e-02  2.56960243e-02 -7.07414187e-03\n",
      " -5.73843159e-02  4.12839241e-02 -5.91503903e-02  5.89021668e-02\n",
      " -4.41697724e-02  4.65081669e-02 -3.15814540e-02  5.58312051e-02\n",
      "  5.54578826e-02 -5.96533082e-02  4.06407677e-02  4.83759586e-03\n",
      " -4.96768653e-02 -1.00944333e-01  3.40078361e-02  4.13273321e-03\n",
      " -2.93528708e-03  2.11837888e-02 -3.73962373e-02 -2.79067252e-02\n",
      " -4.61767539e-02  5.26138656e-02 -2.79734898e-02 -1.62379295e-01\n",
      "  6.61042780e-02  1.72274280e-02 -5.45111625e-03  4.74473834e-02\n",
      " -3.82237621e-02 -3.96896936e-02  1.34544978e-02  4.49653789e-02\n",
      "  4.53669764e-03  2.82978602e-02  8.36632997e-02 -1.00858063e-02\n",
      " -1.19354032e-01 -3.84624489e-02  4.82858717e-02 -9.46083516e-02\n",
      "  1.91854183e-02 -9.96518359e-02 -6.30596951e-02  3.02696265e-02\n",
      "  1.17402598e-02 -4.78372760e-02 -6.20272057e-03 -3.32850814e-02\n",
      " -4.04390739e-03  1.28307128e-02  4.05254662e-02  7.56477043e-02\n",
      "  2.92434953e-02  2.84270495e-02 -2.78938077e-02  1.66857820e-02\n",
      " -2.47961674e-02 -6.83651194e-02  2.89967898e-02 -5.39867748e-33\n",
      " -2.69011874e-03 -2.65068822e-02 -6.47898240e-04 -8.46198015e-03\n",
      " -7.35154748e-02  4.94083343e-03 -5.97841851e-02  1.03438096e-02\n",
      "  2.12901994e-03 -2.88213813e-03 -3.17076594e-02 -9.42363665e-02\n",
      "  3.03019676e-02  7.00226873e-02  4.50685397e-02  3.69439311e-02\n",
      "  1.13593889e-02  3.53027098e-02  5.50449872e-03  1.34414493e-03\n",
      "  3.46122938e-03  7.75048062e-02  5.45112565e-02 -7.92055577e-02\n",
      " -9.31696445e-02 -4.03398350e-02  3.10668889e-02 -3.83081809e-02\n",
      " -5.89442514e-02  1.93331987e-02 -2.67159995e-02 -7.91938379e-02\n",
      "  1.04206440e-04  7.70621374e-02  4.16603498e-02  8.90932828e-02\n",
      "  3.56843062e-02 -1.09152989e-02  3.71498689e-02 -2.07070448e-02\n",
      " -2.46100686e-02 -2.05025468e-02  2.62201596e-02  3.43590453e-02\n",
      "  4.39251065e-02 -8.20514280e-03 -8.40710774e-02  4.24170792e-02\n",
      "  4.87498827e-02  5.95384464e-02  2.87747607e-02  3.37638333e-02\n",
      " -4.07442860e-02 -1.66370091e-03  7.91927576e-02  3.41088697e-02\n",
      " -5.72867575e-04  1.87749956e-02 -1.36964004e-02  7.38332868e-02\n",
      "  5.74467122e-04  8.33505243e-02  5.60811013e-02 -1.13710966e-02\n",
      "  4.42611463e-02  2.69581806e-02 -4.80536111e-02 -3.15087400e-02\n",
      "  7.75226131e-02  1.81773584e-02 -8.83005187e-02 -7.85518158e-03\n",
      " -6.22243024e-02  7.19372705e-02 -2.33475026e-02  6.52480638e-03\n",
      " -9.49528441e-03 -9.88312811e-02  4.01306227e-02  3.07396799e-02\n",
      " -2.21607331e-02 -9.45911258e-02  1.02368053e-02  1.02187760e-01\n",
      " -4.12960127e-02 -3.15778069e-02  4.74751852e-02 -1.10209838e-01\n",
      "  1.69614796e-02 -3.71709168e-02 -1.03262132e-02 -4.72538657e-02\n",
      " -1.20214382e-02 -1.93255283e-02  5.79292290e-02  4.23866044e-34\n",
      "  3.92013006e-02  8.41361359e-02 -1.02946714e-01  6.92259744e-02\n",
      "  1.68820862e-02 -3.26760523e-02  9.65958182e-03  1.80899519e-02\n",
      "  2.17939690e-02  1.63188688e-02 -9.69292372e-02  3.74852889e-03\n",
      " -2.38457210e-02 -3.44055742e-02  7.11962357e-02  9.21936822e-04\n",
      " -6.23862678e-03  3.23754251e-02 -8.90400377e-04  5.01907570e-03\n",
      " -4.24537659e-02  9.89084244e-02 -4.60321009e-02  4.69704866e-02\n",
      " -1.75283886e-02 -7.02517387e-03  1.32743753e-02 -5.30151911e-02\n",
      "  2.66404031e-03  1.45819271e-02  7.43345264e-03 -3.07131633e-02\n",
      " -2.09416877e-02  8.24110359e-02 -5.15894294e-02 -2.71178093e-02\n",
      "  1.17583014e-01  7.72505859e-03 -1.89522970e-02  3.94559652e-02\n",
      "  7.17360452e-02  2.59117167e-02  2.75191888e-02  9.50543862e-03\n",
      " -3.02355550e-02 -4.07944582e-02 -1.04028478e-01 -7.97422044e-03\n",
      " -3.64457024e-03  3.29715982e-02 -2.35954411e-02 -7.50519382e-03\n",
      " -5.82234040e-02 -3.17906514e-02 -4.18049097e-02  2.17453502e-02\n",
      " -6.67292029e-02 -4.89104576e-02  4.58518462e-03 -2.66046543e-02\n",
      " -1.12597041e-01  5.11167236e-02  5.48534095e-02 -6.69856742e-02\n",
      "  1.26766264e-01 -8.59488025e-02 -5.94231784e-02 -2.92186323e-03\n",
      " -1.14875473e-02 -1.26025870e-01 -3.48279253e-03 -9.12001729e-02\n",
      " -1.22933082e-01  1.33777289e-02 -4.75775413e-02 -6.57932907e-02\n",
      " -3.39409821e-02 -3.07107717e-02 -5.22034019e-02 -2.35463809e-02\n",
      "  5.90035506e-02 -3.85757573e-02  3.19700986e-02  4.05118577e-02\n",
      "  1.67077780e-02 -3.58281247e-02  1.45688104e-02  3.20138112e-02\n",
      " -1.34843998e-02  6.07819818e-02 -8.31402000e-03 -1.08105941e-02\n",
      "  4.69410941e-02  7.66134188e-02 -4.23400067e-02 -2.11963336e-08\n",
      " -7.25292861e-02 -4.20227498e-02 -6.12374283e-02  5.24666198e-02\n",
      " -1.42363533e-02  1.18487282e-02 -1.40788918e-02 -3.67529988e-02\n",
      " -4.44977432e-02 -1.15140676e-02  5.23316972e-02  2.96651945e-02\n",
      " -4.62780632e-02 -3.70892584e-02  1.89129785e-02  2.04307623e-02\n",
      " -2.24006362e-02 -1.48562454e-02 -1.79504156e-02  4.20008078e-02\n",
      "  1.40942447e-02 -2.83492524e-02 -1.16863012e-01  1.48956673e-02\n",
      " -7.30598753e-04  5.66028431e-02 -2.68740300e-02  1.09106690e-01\n",
      "  2.94565782e-03  1.19267911e-01  1.14212394e-01  8.92973691e-02\n",
      " -1.70255564e-02 -4.99054082e-02 -2.11930759e-02  3.18421498e-02\n",
      "  7.03435987e-02 -1.02929436e-01  8.23816732e-02  2.81968117e-02\n",
      "  3.21146548e-02  3.79108153e-02 -1.09553121e-01  8.19620341e-02\n",
      "  8.73216316e-02 -5.73563762e-02 -2.01708674e-02 -5.69444187e-02\n",
      " -1.30338594e-02 -5.55684529e-02 -1.32966433e-02  8.64012633e-03\n",
      "  5.30012213e-02 -4.06847186e-02  2.71708872e-02 -2.55944603e-03\n",
      "  3.05775460e-02 -4.61865254e-02  4.68033087e-03 -3.64947096e-02\n",
      "  6.80802390e-02  6.65087625e-02  8.49152282e-02 -3.32849063e-02]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine-Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine-Similarity: tensor([[0.5398]])\n"
     ]
    }
   ],
   "source": [
    "emb1 = model.encode(\"I am eating Apple\")\n",
    "emb2 = model.encode(\"I like fruits\")\n",
    "\n",
    "cos_sim = util.cos_sim(emb1, emb2)\n",
    "print(\"Cosine-Similarity:\", cos_sim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcula a `similaridade de cosseno` entre todos os pares"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Repara que a seguir comparamos as similaridade entre cada sentença. </font>\n",
    "\n",
    "Por exemplo:\n",
    "\n",
    "$[1.0000,  0.7553, -0.1050,  0.2474, -0.0704, -0.0333,  0.1707,  0.0476,\n",
    "          0.0630]$\n",
    "\n",
    "Se compara assim: 1_senteça-1_sentença = 1.0000 | 1_senteça-2_sentença = 0.7553 | 1_senteça-3_sentença = -0.1050 | 1_senteça-4_sentença | ...            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.7553, -0.1050,  0.2474, -0.0704, -0.0333,  0.1707,  0.0476,\n",
       "          0.0630],\n",
       "        [ 0.7553,  1.0000, -0.0610,  0.1442, -0.0809, -0.0216,  0.1157,  0.0362,\n",
       "          0.0216],\n",
       "        [-0.1050, -0.0610,  1.0000, -0.1088,  0.0217, -0.0413, -0.0928,  0.0231,\n",
       "          0.0247],\n",
       "        [ 0.2474,  0.1442, -0.1088,  1.0000, -0.0348,  0.0362,  0.7369,  0.0821,\n",
       "          0.1389],\n",
       "        [-0.0704, -0.0809,  0.0217, -0.0348,  1.0000, -0.1654, -0.0592,  0.1961,\n",
       "          0.2564],\n",
       "        [-0.0333, -0.0216, -0.0413,  0.0362, -0.1654,  1.0000,  0.0769, -0.0380,\n",
       "         -0.0895],\n",
       "        [ 0.1707,  0.1157, -0.0928,  0.7369, -0.0592,  0.0769,  1.0000,  0.0495,\n",
       "          0.1191],\n",
       "        [ 0.0476,  0.0362,  0.0231,  0.0821,  0.1961, -0.0380,  0.0495,  1.0000,\n",
       "          0.6433],\n",
       "        [ 0.0630,  0.0216,  0.0247,  0.1389,  0.2564, -0.0895,  0.1191,  0.6433,\n",
       "          1.0000]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cosine similarity between all pairs\n",
    "sentences = ['A man is eating food.',\n",
    "          'A man is eating a piece of bread.',\n",
    "          'The girl is carrying a baby.',\n",
    "          'A man is riding a horse.',\n",
    "          'A woman is playing violin.',\n",
    "          'Two men pushed carts through the woods.',\n",
    "          'A man is riding a white horse on an enclosed ground.',\n",
    "          'A monkey is playing drums.',\n",
    "          'Someone in a gorilla costume is playing a set of drums.'\n",
    "          ]\n",
    "\n",
    "# Codificamos (Encode) todas as sentences\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Compute cosine similarity between all pairs\n",
    "cos_sim = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor(0.7553), 0, 1),\n",
       " (tensor(-0.1050), 0, 2),\n",
       " (tensor(0.2474), 0, 3),\n",
       " (tensor(-0.0704), 0, 4),\n",
       " (tensor(-0.0333), 0, 5),\n",
       " (tensor(0.1707), 0, 6),\n",
       " (tensor(0.0476), 0, 7),\n",
       " (tensor(0.0630), 0, 8),\n",
       " (tensor(-0.0610), 1, 2),\n",
       " (tensor(0.1442), 1, 3),\n",
       " (tensor(-0.0809), 1, 4),\n",
       " (tensor(-0.0216), 1, 5),\n",
       " (tensor(0.1157), 1, 6),\n",
       " (tensor(0.0362), 1, 7),\n",
       " (tensor(0.0216), 1, 8),\n",
       " (tensor(-0.1088), 2, 3),\n",
       " (tensor(0.0217), 2, 4),\n",
       " (tensor(-0.0413), 2, 5),\n",
       " (tensor(-0.0928), 2, 6),\n",
       " (tensor(0.0231), 2, 7),\n",
       " (tensor(0.0247), 2, 8),\n",
       " (tensor(-0.0348), 3, 4),\n",
       " (tensor(0.0362), 3, 5),\n",
       " (tensor(0.7369), 3, 6),\n",
       " (tensor(0.0821), 3, 7),\n",
       " (tensor(0.1389), 3, 8),\n",
       " (tensor(-0.1654), 4, 5),\n",
       " (tensor(-0.0592), 4, 6),\n",
       " (tensor(0.1961), 4, 7),\n",
       " (tensor(0.2564), 4, 8),\n",
       " (tensor(0.0769), 5, 6),\n",
       " (tensor(-0.0380), 5, 7),\n",
       " (tensor(-0.0895), 5, 8),\n",
       " (tensor(0.0495), 6, 7),\n",
       " (tensor(0.1191), 6, 8),\n",
       " (tensor(0.6433), 7, 8)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adicionamos todos os pares a uma lista com sua pontuação de similaridade de cosseno\n",
    "all_sentence_combinations = []\n",
    "\n",
    "for i in range(len(cos_sim)-1):\n",
    "    for j in range(i + 1, len(cos_sim)):\n",
    "        all_sentence_combinations.append((cos_sim[i][j], i, j))\n",
    "all_sentence_combinations       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os 5 pares mais semelhantes: \n",
      "A man is eating food. \t A man is eating a piece of bread. \t 0.7553\n",
      "A man is riding a horse. \t A man is riding a white horse on an enclosed ground. \t 0.7369\n",
      "A monkey is playing drums. \t Someone in a gorilla costume is playing a set of drums. \t 0.6433\n",
      "A woman is playing violin. \t Someone in a gorilla costume is playing a set of drums. \t 0.2564\n",
      "A man is eating food. \t A man is riding a horse. \t 0.2474\n"
     ]
    }
   ],
   "source": [
    "# Lista de classificação pela maior pontuação de similaridade de cosseno\n",
    "all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "print(\"Os 5 pares mais semelhantes: \")\n",
    "for score, i, j in all_sentence_combinations[0: 5]:\n",
    "    print(\"{} \\t {} \\t {:.4f}\".format(sentences[i], sentences[j], cos_sim[i][j]))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pesquisa Semântica"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"orange\">A pesquisa semântica denota a pesquisa com significado, diferente da `pesquisa lexical`, na qual o mecanismo de pesquisa procura correspondências literais das palavras de consulta ou variantes delas, sem entender o significado geral da consulta.</font>\n",
    "\n",
    "\n",
    "\n",
    "Entãop, a `pesquisa semântica` descreve a tentativa de um mecanismo de pesquisa de gerar os resultados SERP (`Search Engine Results Page`) mais precisos possíveis, com base na intenção do pesquisador, no contexto da consulta e na relação entre as palavras . Isso é importante porque: As pessoas dizem coisas e questionam coisas de diferentes maneiras, idiomas e tons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('clips/mfaq') # Modelo pré-treinado do HuggingFace --> https://huggingface.co/clips/mfaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How many models can I host on HuggingFace?\"\n",
    "\n",
    "answer_1 = \"All plans come with unlimited private models and datasets.\"\n",
    "answer_2 = \"AutoNLP is an automatic way to train and deploy state-of-the-art NLP models, seamlessly integrated with the Hugging Face ecosystem.\"\n",
    "answer_3 = \"Based on how much training data and model variants are created, we send you a compute cost and payment link - as low as $10 per job.\"\n",
    "\n",
    "\n",
    "query_embedding = model.encode(question)\n",
    "corpus_embeddings = model.encode([answer_1, answer_2, answer_3])\n",
    "\n",
    "\n",
    "print(util.semantic_search(query_embedding, corpus_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_embeddings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edf6b0502c5e0317890cf8e032bc40a2d819416c0ad8d6668597893c0d15cade"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
